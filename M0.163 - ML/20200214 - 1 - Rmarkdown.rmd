---
title: "Managing and Understanding Data"
author: "Jose Felix Rojas Cabeza"
date: "2/24/2020"
output:
  pdf_document: default
  html_document: default
  word_document: default
bibliography: scholar.bib
---

```{r setup, include=FALSE}
require(knitr)
# include this code chunk as-is to set options
opts_chunk$set(comment = NA, prompt = TRUE, tidy = FALSE, 
               fig.width = 7, fig.height = 7, echo = TRUE, 
               message = FALSE, warning = FALSE, cache=TRUE)
Sys.setlocale("LC_TIME", "C")
```

```{r paquetes, include=FALSE}
#if(!(require())) install.packages("")
```

> * Primera toma de contacto con un informe dinámico donde se muestra algunas de sus caracteristicas.
> * Son diferentes trozos de un libro.
> * Se lee un archivo csv

-----------------------------------------------------------

`r Sys.Date()`

By the end of this notes, you will understand:

* The basic R data structures and how to use them to store and extract data

* How to get data into R from a variety of source formats
* Common methods for understanding and visualizing complex data

# R data structures

The R data structures used most frequently in machine learning are *vectors*, *factors*, *lists*, *arrays*, and *data frames*.

To find out more about machine learning see [@andrieu2003introduction;@goldberg1988genetic].

## Vectors 

The fundamental R data structure is the **vector**, which stores an ordered set of
values called **elements**. A vector can contain any number of elements. However, all
the elements must be of the same type; for instance, a vector cannot contain both
numbers and text.

There are several vector types commonly used in machine learning:`integer`(numbers without decimals), `numeric` (numbers with decimals), `character` (text data),
or `logical` (`TRUE` or `FALSE` values). There are also two special values: `NULL`, which is
used to indicate the absence of any value, and `NA`, which indicates a missing value.


...

...

...


Create vectors of data for three medical patients:


```{r chunk_1}
# create vectors of data for three medical patients
subject_name <- c("John Doe", "Jane Doe", "Steve Graves")
temperature <- c(98.1, 98.6, 101.4)
flu_status <- c(FALSE, FALSE, TRUE)
```

# Exploring and understanding data

After collecting data and loading it into R data structures, the next step in the machine learning process involves examining the data in detail. It is during this step that you will begin to explore the data’s features and examples, and realize the peculiarities that make your data unique. The better you understand your data, the better you will be able to match a machine learning model to your learning problem. The best way to understand the process of data exploration is by example. In this section, we will explore the **usedcars.csv** dataset, which contains actual data about used cars recently advertised for sale on a popular U.S. website.

...

...

...

Since the dataset is stored in CSV form, we can use the read.csv() function to load the data into an R data frame:
```{R chunk_2}
##### Exploring and understanding data --------------------

## data exploration example using used car data
usedcars <- read.csv("C:/Users/josef/Dropbox/Documents/Personal/UOC/3er Cuatrimestre/M0.163-ML/Unidad 1/usedcars.csv", stringsAsFactors = FALSE)
```

## Exploring the structure of data
One of the first questions to ask in your investigation should be about how data is organized. If you are fortunate, your source will provide a **data dictionary**, a document that describes the data’s features. In our case, the used car data does not come with this documentation, so we’ll need to create our own.

```{R chunk_3}
# get structure of used car data
str(usedcars)
```

## Show some registers
```{R chunk_4}
# Table of 6 first registers
kable(head(usedcars), caption = "6 first registers of data")
```

## Exploring numeric variables
```{R chunk_5}
## Exploring numeric variables -----

# summarize numeric variables
summary(usedcars$year)
summary(usedcars[c("price", "mileage")])

# Calculate the mean income
(36000 + 44000 + 56000) / 3

mean(c(36000,44000,56000))

# the median income
median(c(36000, 44000, 56000))

# the min/max of used car prices
range(usedcars$price)

# the difference of the range
diff(range(usedcars$price))

# IQR for used car prices
IQR(usedcars$price)

# use quantile to calculate five-number summary
quantile(usedcars$price)

# the 99th percentile
quantile(usedcars$price, probs = c(0.01, 0.99))

# quintiles
quantile(usedcars$price, seq(from = 0, to = 1, by = 0.20))
```

## Table with information about mileage and price
```{R chunk_6}
mileage<-summary(usedcars$mileage)
price<-summary(usedcars$price)
kable(rbind(mileage,price), caption= "Descriptive statistic: mileage and price")
```

## Some descriptive graphics
```{R chunk_7}
par(mfrow=c(2,2))
hist(usedcars$mileage, xlab="Mileage", main="Histogram of mileage",col="grey85")
hist(usedcars$price, xlab="Price", main="Histogram of price",col="grey85")
usedcars$transmission <- factor(usedcars$transmission)
plot(usedcars$mileage, usedcars$price, pch=16,
     col=usedcars$transmission,xlab="Mileage", ylab="Price")
legend("topright", pch=16, c("AUTO","MANUAL"), col=1:2, cex=0.5)
```
<center>Descriptive graphics</center>

## Visualizing numeric variables - boxplots

```{R chunk_8}
# boxplot of used car prices and mileage
boxplot(usedcars$price, main="Boxplot of Used Car Prices",ylab="Price ($)")
```
<center>Boxplot of prices</center>

```{R chunk_9}
boxplot(usedcars$mileage, main="Boxplot of Used Car Mileage",
      ylab="Odometer (mi.)")
```
<center>Boxplot of Mileage</center>
```{R chunk_10}
# histograms of used car prices and mileage
hist(usedcars$price, main = "Histogram of Used Car Prices",
     xlab = "Price ($)")
```
<center>Histogram of Used Car Prices</center>
```{R chunk_11}
hist(usedcars$mileage, main = "Histogram of Used Car Mileage",
     xlab = "Odometer (mi.)")
```
<center>Histogram of mileage</center>
```{R chunk_12}
# variance and standard deviation of the used car data
var(usedcars$price)

sd(usedcars$price)

var(usedcars$mileage)

sd(usedcars$mileage)
```

## Measuring spread - quartiles and the five-number summary

The **five-number summary** is a set of five statistics that roughly depict the spread of a dataset. All five of the statistics are included in the output of the summary() function. Written in order, they are:

1. Minimum (`Min.`)
2. First quartile, or Q1 (`1st Qu.`)
3. Median, or Q2 (`Median`)
4. Third quartile, or Q3 (`3rd Qu.`)
5. Maximum (`Max.`)

## Measuring spread - variance and standard deviation

In order to calculate the standard deviation, we must first obtain the **variance**, which is defined as the average of the squared differences between each value and the mean value. In mathematical notation, the variance of a set of `n` values of `x` is defined by the following formula. The Greek letter `mu` $(\mu)$ (similar in appearance to an m) denotes the mean of the values, and the variance itself is denoted by the Greek letter `sigma` $(\sigma)$ squared (similar to a b turned sideways):

\[ Var(X) = \sigma^2 = \frac{1}{n} \sum^n_{i=1}(x_i-\mu)^2 \]

The standard deviation is the square root of the variance, and is denoted by `sigma` as shown in the following formula:

\[ StdDev(X) = \sigma = \sqrt{\frac{1}{n}\sum^n_{i=1}(x_i-\mu)^2} \]

*Note.* For more details on using mathematical expressions in Latex (R Markdown) see <Br /> https://es.sharelatex.com/learn/Mathematical_expressions.

## Addenda

All these these methods should be used to analyze data and solve problems like the ozone layer [-@lopez1986capa] or socioeconomic problems like the precarious work [-@beck2000nuevo].

The main goal is to accomplish long-term growth as stated in Doppelhofer, Miller, and others [-@doppelhofer2004determinants].

# References











